{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gaXcOsnwbb-r"
   },
   "source": [
    "Proyecto Final\n",
    "==============\n",
    "\n",
    "### Tratamiento de Datos\n",
    "### Máster de Ing. de Telecomunicación\n",
    "\n",
    "# Autores\n",
    "\n",
    "Juan Manuel Espinosa Moral ([100406523@alumnos.uc3m.es](mailto:100406523@alumnos.uc3m.es))\n",
    "\n",
    "José Manuel García Núñez ([100544621@alumnos.uc3m.es](mailto:100544621@alumnos.uc3m.es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hTPdyX5-bb-w",
    "outputId": "0340b141-05d1-4c2f-adc5-7b0034300595",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Google Drive integration\n",
    "\n",
    "# Libraries to work with Google Drive and the file system\n",
    "from google.colab import drive\n",
    "import os, sys\n",
    "\n",
    "# Drive is mounted\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "# Current directory is shown\n",
    "print(os.getcwd())\n",
    "\n",
    "# We change to work directory\n",
    "directory_path = \"/content/drive/MyDrive/Colab Notebooks/proyecto_td/\"  # Define directory_path here\n",
    "if not os.path.exists(directory_path):\n",
    "  os.makedirs(directory_path)\n",
    "  print(f\"Directory created: {directory_path}\")\n",
    "\n",
    "os.chdir(directory_path) # Now change to the directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpdJW6D0kTLy"
   },
   "source": [
    "# 1. Análisis de Variables de Entrada\n",
    "Carga del dataset: datos del archivo JSON.\n",
    "Categorías: las más frecuentes.\n",
    "Rating y visualizaciones.\n",
    "Análisis de correlación: categorias y variables de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hrXzyjOSl_ip",
    "outputId": "6f9cb0cc-123d-427c-dd70-443bd69ca066"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar el archivo JSON\n",
    "df = pd.read_json(\"full_format_recipes.json\")\n",
    "\n",
    "# Explorar las categorías más frecuentes\n",
    "category_counts = df['categories'].explode().value_counts()\n",
    "print(\"Categorías más frecuentes:\\n\", category_counts.head())\n",
    "\n",
    "# Visualizar las categorías más frecuentes\n",
    "category_counts.head(10).plot(kind='bar', title=\"Frecuencia de las categorías\")\n",
    "plt.ylabel(\"Número de recetas\")\n",
    "plt.show()\n",
    "\n",
    "# Analizar la relación entre categorías y ratings, filtrando por las más frecuentes\n",
    "df_exploded = df.explode('categories')  # Expandir listas de categorías\n",
    "df_exploded = df_exploded.reset_index(drop=True)  # Resetear el índice\n",
    "\n",
    "# Filtrar por las 10 categorías más frecuentes\n",
    "top_categories = category_counts.head(10).index.tolist()\n",
    "df_filtered = df_exploded[df_exploded['categories'].isin(top_categories)]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='categories', y='rating', data=df_filtered)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Distribución de ratings por categoría (Top 10)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "id": "Dl_EY8F8Om-n",
    "outputId": "909b4b1c-70c4-461e-9fef-7aaf73b564a9"
   },
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame\n",
    "correlation = df[['fat', 'protein', 'calories', 'sodium', 'rating']].corr()\n",
    "\n",
    "print(correlation)\n",
    "\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NDXZqe44k0e1",
    "outputId": "8bd1734f-5630-490c-92ab-d2154aafc8c8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar el archivo JSON\n",
    "df = pd.read_json(\"full_format_recipes.json\")\n",
    "\n",
    "# Explorar las categorías más frecuentes\n",
    "category_counts = df['categories'].explode().value_counts()\n",
    "print(\"Categorías más frecuentes:\\n\", category_counts.head())\n",
    "\n",
    "# Visualizar las categorías más frecuentes\n",
    "category_counts.head(10).plot(kind='bar', title=\"Frecuencia de las categorías\")\n",
    "plt.ylabel(\"Número de recetas\")\n",
    "plt.show()\n",
    "\n",
    "# Analizar la relación entre categorías y ratings\n",
    "df_exploded = df.explode('categories')  # Expandir listas de categorías\n",
    "# Reset the index to avoid duplicate index values\n",
    "df_exploded = df_exploded.reset_index(drop=True)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='categories', y='rating', data=df_exploded)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Distribución de ratings por categoría\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "U6qXseZePSY5",
    "outputId": "689fe783-6244-45af-d9fb-0bde559fcac6"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.scatter(df['fat'], df['rating'])\n",
    "plt.xscale('log')  # Apply logarithmic scale to x-axis\n",
    "plt.xlabel('Fat (grams) - Log Scale')\n",
    "plt.ylabel('Rating')\n",
    "plt.title('Fat vs. Rating (Log Scale)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKofPTudPSJw"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "TWYtY4TQQNjV",
    "outputId": "2e2acba8-202c-4891-8bdc-22f563c3ec9d"
   },
   "outputs": [],
   "source": [
    "# Define the bins for calories\n",
    "bins = [0, 200, 400, 600, 800, 1000, float('inf')]\n",
    "labels = ['0-200', '201-400', '401-600', '601-800', '801-1000', '1001+']\n",
    "\n",
    "# Create a new column with the calorie bins\n",
    "df['calorie_bins'] = pd.cut(df['calories'], bins=bins, labels=labels)\n",
    "\n",
    "average_ratings = df.groupby('calorie_bins')['rating'].mean()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(average_ratings.index, average_ratings.values)\n",
    "plt.xlabel('Calorie Range')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.title('Average Rating vs. Calories')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "djjhEDQaQcpl",
    "outputId": "026c0530-296f-47df-e831-1520300560a8"
   },
   "outputs": [],
   "source": [
    "# Create a new column with the calorie bins\n",
    "bins_fat = [0, 10, 20, 30, 40, 50, float('inf')]\n",
    "labels_fat = ['0-10', '11-20', '21-30', '31-40', '41-50', '51+']\n",
    "\n",
    "df['fat_bins'] = pd.cut(df['fat'], bins=bins_fat, labels=labels_fat)\n",
    "\n",
    "average_ratings = df.groupby('fat_bins')['rating'].mean()\n",
    "\n",
    "plt.bar(average_ratings.index, average_ratings.values)\n",
    "plt.xlabel('Fat Range')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.title('Average Rating vs. Fat')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "gVrn6Dl_QcMU",
    "outputId": "e5b17a63-93de-4201-a2e4-01050517a91d"
   },
   "outputs": [],
   "source": [
    "# Create a new column with the calorie bins\n",
    "bins_protein = [0, 10, 20, 30, 40, 50, float('inf')]\n",
    "labels_protein = ['0-10', '11-20', '21-30', '31-40', '41-50', '51+']\n",
    "\n",
    "df['protein_bins'] = pd.cut(df['protein'], bins=bins_protein, labels=labels_protein)\n",
    "\n",
    "average_ratings = df.groupby('protein_bins')['rating'].mean()\n",
    "\n",
    "plt.bar(average_ratings.index, average_ratings.values)\n",
    "plt.xlabel('Protein Range')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.title('Average Rating vs. Protein')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oegguacSRuw_"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OhObN5-FRx7h",
    "outputId": "7ef7af8e-7de1-47c3-d180-9ece673711b8"
   },
   "outputs": [],
   "source": [
    "top_20_categories = df_exploded['categories'].value_counts().head(20).index.tolist()\n",
    "df_filtered = df_exploded[df_exploded['categories'].isin(top_20_categories)]\n",
    "\n",
    "variables = ['fat', 'protein', 'calories', 'sodium', 'rating']\n",
    "for variable in variables:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x='categories', y=variable, data=df_filtered)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(f'{variable.capitalize()} Distribution by Top 20 Categories')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73Cyg0IoTfaE",
    "outputId": "7a4440be-faa7-49f7-e0c6-e2fcb4d30282"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "\n",
    "# Load the spaCy language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess_text(text, use_spacy=False):\n",
    "    \"\"\"\n",
    "    Preprocesar texto: limpiar, tokenizar, lematizar y eliminar stopwords.\n",
    "\n",
    "    Args:\n",
    "    - text (str | list | float): Texto a procesar o lista de textos.\n",
    "    - use_spacy (bool): Usar SpaCy para el procesamiento en lugar de NLTK.\n",
    "\n",
    "    Returns:\n",
    "    - str: Texto preprocesado.\n",
    "    \"\"\"\n",
    "    # Si el texto es NaN o no es string/list, convertirlo a cadena vacía\n",
    "    if not isinstance(text, (str, list)):\n",
    "        text = ''\n",
    "\n",
    "    # Si el texto es una lista, unir sus elementos en una sola cadena\n",
    "    if isinstance(text, list):\n",
    "        text = ' '.join(text)\n",
    "\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "\n",
    "    # Eliminar caracteres especiales y números\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "\n",
    "    if use_spacy:\n",
    "        # Usar SpaCy para tokenización y lematización\n",
    "        doc = nlp(text)\n",
    "        tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    else:\n",
    "        # Tokenizar usando NLTK\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "\n",
    "        # Eliminar stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "        # Lematizar\n",
    "        lemmatizer = nltk.WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    # Unir tokens de nuevo en un solo string\n",
    "    processed_text = ' '.join(tokens)\n",
    "    return processed_text\n",
    "\n",
    "# Manejar valores NaN en la columna 'categories'\n",
    "df['categories'] = df['categories'].fillna('')\n",
    "\n",
    "# Aplicar el pipeline al conjunto de datos\n",
    "df['processed_categories'] = df['categories'].apply(preprocess_text, use_spacy=True)\n",
    "\n",
    "# Inspeccionar el resultado\n",
    "print(df[['categories', 'processed_categories']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PxtNOxq-lPT_",
    "outputId": "80b93919-1d7b-4d63-bfe1-bdaf323eb781"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Assuming 'df' contains your DataFrame with the 'processed_categories' column\n",
    "\n",
    "# Create a TfidfVectorizer object\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the preprocessed text\n",
    "tfidf_matrix = vectorizer.fit_transform(df['processed_categories'])\n",
    "\n",
    "# Get feature names (words)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame (optional)\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names, index=df.index)\n",
    "\n",
    "# Print or inspect the resulting TF-IDF matrix or DataFrame\n",
    "print(tfidf_df)  # Or inspect tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Utijy9gCn2Vu",
    "outputId": "459cfc9d-7a7f-476b-bbe4-9437002a5097"
   },
   "outputs": [],
   "source": [
    "!pip install nltk==3.8.1\n",
    "!pip install gensim\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "# Preparado de datos de texto\n",
    "sentences = [row.split() for row in df['processed_categories']]\n",
    "\n",
    "# Entrenamiento del modelo con las condiciones normales\n",
    "\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=5, workers=4)\n",
    "\n",
    "# 3. Obtén los vectores de palabras y promediados\n",
    "\n",
    "def get_category_vector(category_words):\n",
    "  \"\"\"Obtiene el vector promedio para una categoría.\"\"\"\n",
    "  vectors = [model.wv[word] for word in category_words if word in model.wv]\n",
    "  if vectors:\n",
    "    return np.mean(vectors, axis=0)\n",
    "  else:\n",
    "    return np.zeros(model.vector_size)  # Vector de ceros si no hay palabras en el vocabulario\n",
    "\n",
    "df['category_vector'] = df['processed_categories'].apply(lambda x: get_category_vector(x.split()))\n",
    "\n",
    "# Muestra los primeros 5 elementos del vector para las primeras 5 filas\n",
    "for index in range(5):\n",
    "  print(f\"Fila {index}: {df['category_vector'][index][:5]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1UZRRQqq1SY"
   },
   "source": [
    "Testing de los metodos de vectorización TF-IDF y vec2sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_vLMNOVwq-gF",
    "outputId": "85ef57ac-3d41-4b08-925d-35322d3f9721"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# Crear un diccionario de palabras y sus pesos TF-IDF\n",
    "word_weights = dict(zip(feature_names, tfidf_matrix.sum(axis=0).tolist()[0]))\n",
    "\n",
    "# nube de palabras\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_weights)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reducir la dimensionalidad a 2D\n",
    "pca = PCA(n_components=2)\n",
    "vectors_2d = pca.fit_transform(df['category_vector'].to_list())\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(vectors_2d[:, 0], vectors_2d[:, 1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
