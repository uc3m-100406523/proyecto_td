{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# **Text Vectorization II**\n","\n","---\n","### Natural Language Processing\n","Date: Nov 16, 2022\n","\n","Author: Lorena Calvo-Bartolomé (lcalvo@pa.uc3m.es)\n","\n","Version 1.0\n","\n","---\n","This notebook is based on the Gensim documentation and tutorials, as well as on Daniel Voigt Godoy's book \"Deep Learning with Pytorch Step-by-Step, Volume III: Sequences \\& NLP\".\n","\n","Our goal here is to provide a basic overview of the following text vectorization techniques:\n","\n","\n","*   Word2Vec\n","*   GloVe\n","*   FastText\n","*   ELMo\n","\n","as well as how to use them to solve a Text Classification task."],"metadata":{"id":"RRzzl3bhJ4mk"}},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"},"id":"hTPdyX5-bb-w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732297702591,"user_tz":-60,"elapsed":22608,"user":{"displayName":"JUAN MANUEL ESPINOSA MORAL","userId":"03725791287650385729"}},"outputId":"811a0d20-90da-478d-b7ca-5ed1ff6d07a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content\n"]}],"source":["# Google Drive integration\n","\n","# Libraries to work with Google Drive and the file system\n","from google.colab import drive\n","import os, sys\n","\n","# Drive is mounted\n","drive.mount(\"/content/drive\")\n","\n","# Current directory is shown\n","print(os.getcwd())\n","\n","# We change to work directory\n","directory_path = \"/content/drive/MyDrive/Colab Notebooks/proyecto_td/Text_Vectorization_II_students/\"  # Define directory_path here\n","if not os.path.exists(directory_path):\n","  os.makedirs(directory_path)\n","  print(f\"Directory created: {directory_path}\")\n","os.chdir(directory_path)"]},{"cell_type":"code","source":["%pip install gensim==4.2.0 pqkmeans"],"metadata":{"id":"T2Ng8wwPQYUn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733574192729,"user_tz":-60,"elapsed":8703,"user":{"displayName":"JUAN MANUEL ESPINOSA MORAL","userId":"03725791287650385729"}},"outputId":"1b25afc9-6237-4fa1-a307-c32aef5d1585"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gensim==4.2.0\n","  Downloading gensim-4.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\n","Collecting pqkmeans\n","  Downloading pqkmeans-1.0.6.tar.gz (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.3/224.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from gensim==4.2.0) (1.26.4)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from gensim==4.2.0) (1.13.1)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim==4.2.0) (7.0.5)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pqkmeans) (1.5.2)\n","Collecting pipe<2.0 (from pqkmeans)\n","  Downloading pipe-1.6.0-py2.py3-none-any.whl.metadata (9.0 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pqkmeans) (1.16.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim==4.2.0) (1.17.0)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pqkmeans) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pqkmeans) (3.5.0)\n","Downloading gensim-4.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pipe-1.6.0-py2.py3-none-any.whl (6.8 kB)\n","Building wheels for collected packages: pqkmeans\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pqkmeans \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Building wheel for pqkmeans (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n","\u001b[31m  ERROR: Failed building wheel for pqkmeans\u001b[0m\u001b[31m\n","\u001b[0mFailed to build pqkmeans\n","\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pqkmeans)\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LiLrSlf2J4JP","colab":{"base_uri":"https://localhost:8080/","height":425},"executionInfo":{"status":"error","timestamp":1733574195654,"user_tz":-60,"elapsed":2929,"user":{"displayName":"JUAN MANUEL ESPINOSA MORAL","userId":"03725791287650385729"}},"outputId":"7e3f6dc8-5b66-4b2c-aeeb-2a388d1a4abf"},"outputs":[{"output_type":"error","ename":"OSError","evalue":"'seaborn-whitegrid' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/style/core.py\u001b[0m in \u001b[0;36muse\u001b[0;34m(style)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0mstyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rc_params_in_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36m_rc_params_in_file\u001b[0;34m(fname, transform, fail_on_error)\u001b[0m\n\u001b[1;32m    865\u001b[0m     \u001b[0mrc_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_or_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36m_open_file_or_url\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'seaborn-whitegrid'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-cbeac0ddca38>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"InlineBackend.figure_format = 'retina'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Figures style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'seaborn-whitegrid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"darkgrid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_palette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"deep\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/style/core.py\u001b[0m in \u001b[0;36muse\u001b[0;34m(style)\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0mstyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rc_params_in_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                 raise OSError(\n\u001b[0m\u001b[1;32m    140\u001b[0m                     \u001b[0;34mf\"{style!r} is not a valid package style, path of style \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                     \u001b[0;34mf\"file, URL of style file, or library style name (library \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: 'seaborn-whitegrid' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)"]}],"source":["# Common imports\n","import os\n","import numpy as np\n","import pandas as pd\n","from termcolor import colored\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import tqdm\n","import scipy\n","import gc\n","\n","\n","# Figures plotted inside the notebook\n","%matplotlib inline\n","# High quality figures\n","%config InlineBackend.figure_format = 'retina'\n","# Figures style\n","plt.style.use('seaborn-whitegrid')\n","sns.set_style(\"darkgrid\")\n","sns.color_palette(\"deep\")\n","# Figues size\n","plt.rcParams['figure.figsize'] = [8, 6]\n","\n","# Supress future warnings\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.filterwarnings(action='ignore',module='compress_fasttext')"]},{"cell_type":"code","source":["# To wrap long text lines\n","from IPython.display import HTML, display\n","\n","def set_css():\n","  display(HTML('''\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  '''))\n","get_ipython().events.register('pre_run_cell', set_css)"],"metadata":{"id":"x7lkDl2VKBeX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# For fancy table Display\n","%load_ext google.colab.data_table"],"metadata":{"id":"UrPeKEF9KDc8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path_to_folder = '/content/drive/My Drive/NLP_IA'  # UPDATE THIS ACCORDING TO WHERE YOU WANT TO SAVE THE FILES!!!!"],"metadata":{"id":"W-RqqTiMhLMx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')\n","\n","# Change to assignment directory\n","os.chdir(path_to_folder)"],"metadata":{"id":"r5fhZ7MvKHzm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **1. Data preparation**\n","---\n"],"metadata":{"id":"A9TfSEJqKPNS"}},{"cell_type":"markdown","source":["For this second text vectorization notebook, we will keep working with the **IMDB Dataset of 50K Movie Reviews**. Since we already carried out all the dataset preparation in the previous notebook, we will just load the the dataframe that we saved."],"metadata":{"id":"w4uWbvR8KTdK"}},{"cell_type":"code","source":["import pickle\n","\n","def unpickler(file: str):\n","    \"\"\"Unpickle file\"\"\"\n","    with open(file, 'rb') as f:\n","        return pickle.load(f)\n","\n","corpus_df = unpickler(\"corpus_df_imbdb.pickle\")\n","print(len(corpus_df))"],"metadata":{"id":"t0OPJNeaKSxb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### **Exercise 1**\n","\n","Create a Gensim corpus and obtain its Gensim dictionary. With the latter, save the vocabulary of the corpus as a list. Store the Gensim corpus in a variable named ``corpus``, the Gensim dictionary in a variable named ``D``, and the vocabulary in a variable named ``vocab``.\n","\n","**Hint:** Make use of the Gensim dictionary' method ``token2id`` for obtaining the vocabulary list."],"metadata":{"id":"cSCNgGg4uNlI"}},{"cell_type":"code","source":["# <SOL>\n","\n","# </SOL>\n","\n","print(colored('\\n============= First 10 words in the vocabulary =============', 'blue'))\n","print(vocab[0:20])"],"metadata":{"id":"O2Fj9JDyXW61"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's also save the sentiment of the review in a NumPy array for later use."],"metadata":{"id":"JS6PULrlvFDa"}},{"cell_type":"code","source":["Y = corpus_df['binary_sentiment'].values"],"metadata":{"id":"Zv7xzJqhA73n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **2. Word2Vec**\n","---\n"],"metadata":{"id":"CdKBBiR0K6oN"}},{"cell_type":"markdown","source":["We will use [Gensim's implementation of Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html), which supports both the skip-gram and CBOW models, with either hierarchical softmax or negative sampling. Furthermore, Gensim contains a collection of functions for the exploitation of pre-trained embeddings, which can be either embeddings developed by us or pre-trained models on big corpora."],"metadata":{"id":"jAX4-j_-LxIy"}},{"cell_type":"markdown","source":["### *2.1. Implementation of Word2Vec in Gensim*"],"metadata":{"id":"aDxgclbMLM4-"}},{"cell_type":"markdown","source":["Word2Vec models require a lot of text, e.g., the entire Wikipedia corpus. Nevertheless, we will demonstrate the principles using a small example from our IMDB dataset.\n","\n","Gensim's Word2Vec expects a sequence of sentences (``sentences``) as its input where each sentence is a list of words:\n","\n","```\n","sentences = [['This', 'is', 'the', 'first', 'sentence'], ['This', 'is', 'the', 'second', 'sentence']]\n","```\n","\n","In addition, some of the most important parameters that we may wish to configure are the following:\n","\n","* `vector_size`: The dimensionality of the word vectors, i.e.,  the embedding size. The default is **100**.\n","* `window`: The window size, i.e., the number of adjacent words that are considered in the same context as the target word. The default is **5**.\n","* `min_count`: Ignores all words with a total frequency lower than this.\n","* `sg`: Training algorithm: 1 for skip-gram; otherwise CBOW.\n","\n","Keeping the input as a Python built-in list is convenient, but can use up a lot of RAM when the input is large. Gensim only requires the input to provide sentences sequentially, when iterated over. Hence, we can use the same principle that we utilized in the first notebook of this tutorial at ``2.5. Memory efficient computation``."],"metadata":{"id":"OvHZvVznPjfW"}},{"cell_type":"markdown","source":["##### **Exercise 2**\n","\n","The provided class ``IterableSentence_fromfile`` creates an iterator that yields one sentence (list of utf8 words) after another from the file ``\"imdb_lemmas_clean.txt\"``.\n","\n","Use the sentence iterator to create a Word2Vec skip-gram model named ``model_w2v`` with vector size **200** and window size **5**.  Words must appear in at least **10** documents to be kept in the model. Use a seed of **42**."],"metadata":{"id":"BHLz0opY6po7"}},{"cell_type":"code","source":["%%time\n","from gensim.models import Word2Vec\n","\n","class IterableSentence_fromfile(object):\n","    def __init__(self, filename):\n","        self.__filename = filename\n","\n","    def __iter__(self):\n","        for line in open(self.__filename):\n","            # assume there's one sentence per line, tokens separated by whitespace\n","            yield line.split()\n","\n","sentences = IterableSentence_fromfile(\"imdb_lemmas_clean.txt\") # a memory-friendly iterator\n","\n","# <SOL>\n","\n","vector_size=200\n","window=5\n","min_count=5\n","sg=0\n","seed=42\n","\n","model_w2v = Word2Vec(\n","    sentences=sentences,\n","    vector_size=vector_size,\n","    window=window,\n","    min_count=min_count,\n","    sg=sg,\n","    seed=seed)\n","\n","# </SOL>"],"metadata":{"id":"bD-TghawD6iR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Once the model is trained, it is accessible via the ``wv`` attribute, which is the actual word vector model in which queries can be made.\n","\n","We can see the learned vocabulary of the model through the dictionary ``key_to_index``, that is, the target words for which we have calculated an embedding, as well as the corresponding embeddings for these words, as follows:"],"metadata":{"id":"6dsHfzAPLA6K"}},{"cell_type":"code","source":["print(colored('\\n============= Word2Vec vocabulary =============', 'blue'))\n","words = list(model_w2v.wv.key_to_index)\n","print(words[0:50])\n","print(colored('\\n============= Embedding of the first word =============', 'blue'))\n","print(model_w2v.wv[words[0]])"],"metadata":{"id":"XHQSvI_SFo35"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can save the trained model by calling the ``save()`` function, and we can load it again by calling the ``load()`` method."],"metadata":{"id":"gAZ7LTYasFfE"}},{"cell_type":"code","source":["model_w2v.save(\"model_w2v_imbd_sampling03.model\")\n","\n","# This function will load the model, but we will not be using it here\n","#model_w2v = Word2Vec.load(\"model_w2v_imbd_sampling03.model\")"],"metadata":{"id":"Gvn_5zpwsUaA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Since we are not going to keep with the training at this moment, we do not need the full model state anymore. Hence, we can store the words and their trained embeddings and load them back as ``KeyedVectors``, which is essentially a mapping between keys and vectors. This results in a much smaller and faster object that can be mapped for lightning-fast loading and sharing the vectors in RAM between processes."],"metadata":{"id":"MS57-2OVrxM4"}},{"cell_type":"code","source":["from gensim.models import KeyedVectors\n","\n","# Store just the words + their trained embeddings.\n","word_vectors = model_w2v.wv\n","word_vectors.save(\"model_w2v_imbd_sampling03.wordvectors\")\n","\n","# Load back with memory-mapping = read-only, shared across processes.\n","wv = KeyedVectors.load(\"model_w2v_imbd_sampling03.wordvectors\", mmap='r')"],"metadata":{"id":"m37qaMVGsDRp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's free the memory.\n","\n"],"metadata":{"id":"Iry7Bmb7je23"}},{"cell_type":"code","source":["del model_w2v\n","gc.collect()"],"metadata":{"id":"LXMLquuLjmJQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Since we have represented our words as numerical vectors, we can utilize the Euclidean distance (or cosine similarity) among two word vectors to measure the linguistic or semantic similarity of the corresponding words. To do this, Gensim provides the function ``most_similar`` which returns the most similar words from a given word."],"metadata":{"id":"uoeTBWfuR3qe"}},{"cell_type":"code","source":["wv.most_similar(positive=\"cinema\")"],"metadata":{"id":"_B-J-jsFpFrr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["wv.most_similar(positive=\"restaurant\")"],"metadata":{"id":"qeGSsmMiSiaX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can also check the performance of our model by visualizing the embeddings. However, although embeddings are low-dimensional vectors, even 4 dimensions are too high to visualize. [t-SNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding) (*t-distributed Stochastic Neighbor Embedding*) solves this problem as it allows for visualizing high-dimensional data by reducing them to two or three-dimensional data. The technique takes in the embeddings (or any data) and aims at preserving as much as possible in 2 (or 3) dimensions the distances from the original space of the embedding dimension. This, therefore, helps us to get a feel for the space of word embedding.\n","\n","\n","Sklearn includes an implementation of [t-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) that we can easily use."],"metadata":{"id":"TiTioJ1iWGoe"}},{"cell_type":"code","source":["from sklearn.manifold import TSNE\n","\n","tsne = TSNE(init='random')\n","embed_tsne = tsne.fit_transform(wv.vectors)\n","\n","# We plot only 500 embeddings\n","fig, ax = plt.subplots(figsize=(16, 16))\n","for idx, word in enumerate((list(wv.key_to_index.keys())[:500])):\n","    plt.scatter(*embed_tsne[idx, :], color='steelblue')\n","    plt.annotate(word, (embed_tsne[idx, 0], embed_tsne[idx, 1]), alpha=0.7)\n","\n","plt.grid()"],"metadata":{"id":"a3xzHvHxFvjc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del embed_tsne\n","gc.collect()"],"metadata":{"id":"X8W9Lt63zYe1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["From the above results, we can see that our word2vec model does not do a bad job, but it could still be improved. Certainly, we need to train on a much larger dataset to obtain a coherent embedding structure."],"metadata":{"id":"SuoGxSC1pOnR"}},{"cell_type":"markdown","source":["### *2.2. Sentiment Analysis with ad-hoc trained Word2Vec embeddings*"],"metadata":{"id":"RZI1VQL6oikR"}},{"cell_type":"markdown","source":["Since our data contains reviews and not just words, we need to figure out a way to use the word vectors from the word2vec model to create a vector representation for an entire review. One simple solution to achieve this is to take the mean of all the word vectors present in the review.\n","\n","Since when we constructed our Word2Vec model we filtered out those words which did not have an overall frequency of 10, we may encounter that our reviews contain some words that are not in the vocabulary of the model, i.e., they are out-of-vocabulary words (OOV)."],"metadata":{"id":"XDoSzjZAoqJr"}},{"cell_type":"markdown","source":["##### **Exercise 3**\n","\n","Implement the function ``get_vocabulary_coverage`` which, given a ``KeyedVectors`` object and the Gensim dictionary associated with the reviews, calculates the vocabulary coverage of the model. Take into account the frequency with which the OOV words appear in the reviews.\n","\n","Then, calculate the coverage of the Word2Vec model on the IMDB vocabulary."],"metadata":{"id":"sbTr81jZR2se"}},{"cell_type":"code","source":["def get_vocabulary_coverage(model, gensim_dict):\n","  # <SOL>\n","  # TODO: Implement body\n","  # </SOL>\n","  return coverage\n","\n","# <SOL>\n","# TODO: Use function \"get_vocabulary_coverage\" to calculate coverage and print result\n","# </SOL>"],"metadata":{"id":"fSz5_O2ESPM_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### **Exercise 4**\n","\n","Implement the function ``get_review_vector`` which, given a ``KeyedVectors`` object, and a list of tokens representing a review returns the embedding vector for such a review by taking the average of the vectors of the words present in the given review. Ignore the OOV words.\n","\n","Once you have the function, calculate the reviews' embedding vectors. Save them in a matrix of dimensions $[n_{reviews}, e_{size}]$, where $e_{size}$ is the embedding size of the model."],"metadata":{"id":"i6gP_WtFMu0S"}},{"cell_type":"code","source":["def get_review_vector(model, review):\n","  # <SOL>\n","  # TODO: Implement body\n","  # </SOL>\n","  return vec\n","\n","# <SOL>\n","# TODO: Calculate embedding vectors for each review and save them in a sparse matrix\n","# </SOL>"],"metadata":{"id":"NulBrdHmospa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### **Exercise 5**\n","Classify the reviews based on the Word2Vec embeddings representation with an SVM classifier. Split the data into a $70:30$ ratio for training and test with a $42$ random_state and use ``GridSearchCV`` to find the best hyperparameters values (``C`` and ``kernel``) for the classifier. Consider the grid search of the parameter ``C`` between 1 and 10 in intervals of 2, and try out the ``rbf`` and the ``linear`` kernels. At last, evaluate the performance of the classifier based on  its mean accuracy on the given test data and labels (``score`` function of the SVM classifier)."],"metadata":{"id":"w5YP_5jjYxZj"}},{"cell_type":"code","source":["# <SOL>\n","\n","# </SOL>"],"metadata":{"id":"f-D90EwWFBWx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## *3. GloVe*"],"metadata":{"id":"NJ5xyK2jLSmD"}},{"cell_type":"markdown","source":["### *3.1. Pre-trained GloVe models in Gensim*"],"metadata":{"id":"ccBbDEa1wrQR"}},{"cell_type":"markdown","source":["For a specific NLP task, training our own word vectors may be the optimal strategy. However, it may require a long time, a fast computer with plenty of RAM and disc space, and maybe some experience in fine-tuning the input data and training algorithm. Another option is to just utilize pre-trained word embeddings.\n","\n","For example, Gensim includes functions to exploit a set of [pre-trained *embeddings*](https://github.com/RaRe-Technologies/gensim-data)."],"metadata":{"id":"pIC6JeEftowe"}},{"cell_type":"code","source":["from gensim import downloader\n","\n","print(colored('\\n============= Available pre-trained models in Gensim =============', 'blue'))\n","print(list(downloader.info()['models'].keys()))"],"metadata":{"id":"5tfkmIHeMFJ7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["As we can see above, many of the pretrained models provided by Gensim are GloVe models. The pretrained GloVe embeddings come in many sizes and shapes, with dimensions in the range $[25,30]$, and vocabularies varying between $400,000$ and $2,200,000$ words.\n","\n","Let's use Gensim's downloader to get the ``glove-wiki-gigaword-50``, which is the smallest available GloVe model. It was trained on Wikipedia 2014 and Gigawords, contains $400,000$ vocabulary words and its embeddings have a dimension of $50$."],"metadata":{"id":"nJ1TBheYFy6p"}},{"cell_type":"code","source":["glove = downloader.load('glove-wiki-gigaword-50')\n","\n","print(f\"The dictionary size is {glove.vectors.shape[0]}.\\n\\\n","        Each embedding has a dimension of {glove.vectors.shape[1]}\")"],"metadata":{"id":"EhLKmdwGOa3G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### *3.2. Semantic operations with embeddings*"],"metadata":{"id":"YigTqqzdrz0Y"}},{"cell_type":"markdown","source":["One interesting thing that we can do with word vectors, which is easily perceptible with the GloVe-based embeddings we just loaded, is to perform algebra arithmetic with words. A famous example is the following equation:\n","\n","``\n","queen = (king - man) + woman\n","``\n","\n","That is, the word ``queen`` is the closest word to the operation consisting of subtracting ``man`` from ``king`` and adding the word ``woman``. The quality of \"being a man\" is replaced with that of \"being a woman\", leading to the word queen.\n","\n","We can perform this operation in Gensim as follows:"],"metadata":{"id":"KRIbeDHA6rmq"}},{"cell_type":"code","source":["glove.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"],"metadata":{"id":"Kg3PdFjAdLIx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["synthetic_queen = glove['king'] - glove['man'] + glove['woman']\n","glove.similar_by_vector(synthetic_queen, topn=5)"],"metadata":{"id":"JWAvdvx3-F7f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The above result indicates that the term most comparable to the arithmetic operation result (synthetic queen) is the original word itself. This is pretty typical when conducting word arithmetic operations, which is why we usually omit the original word from the output, thus being the most similar word to our synthetic_queen the actual queen.\n","\n","The general idea here is that the embeddings have learned to **encode abstract dimensions**, like gender, genealogy, or profession. Yet, none of these abstract dimensions correspond to a single numerical dimension. In its 50-dimensional feature space, the model learned to place ``the man`` as far apart from ``woman`` as ``king`` is from ``queen`` (roughly approximating the gender difference between the two). Similarly, the model learned to place ``king`` as far apart from ``man`` as ``queen`` is from ``woman`` (roughly approximating the difference of being a royal). We can visualize this concept when projected in two dimensions as shown below:\n","\n","<img src=\"https://drive.google.com/uc?id=1TO3WS4-RKkL_AO---ZFAEzxcDLHjEMEu\" width=\"40%\">\n","\n","From the figure above, it should be relatively clear that both arrows pointing up (blue) are approximately the same size, thus resulting in the equation below:\n","\n","\\begin{align}\n","    w_{king} - w_{man} &≃ w_{queen} - w_{woman}\\\\\n","    w_{king} - w_{man} &+ w_{woman} ≃ w_{queen}\n","\\end{align}"],"metadata":{"id":"XprnAvcP8qYr"}},{"cell_type":"markdown","source":["We can observe how the word vectors also include information to relate countries with nationalities, months of the year, family relationships, etc."],"metadata":{"id":"IfPNRMvas0V2"}},{"cell_type":"code","source":["result = glove.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n","print('King - Man + Woman = ',result)\n","result = glove.most_similar(positive=['rome', 'france'], negative=['paris'], topn=1)\n","print('France - Paris + Rome = ',result)\n","result = glove.most_similar(positive=['english', 'france'], negative=['french'], topn=1)\n","print('France - french + english = ',result)\n","result = glove.most_similar(positive=['june', 'december'], negative=['november'], topn=1)\n","print('December - November + June = ',result)\n","result = glove.most_similar(positive=['sister', 'man'], negative=['woman'], topn=1)\n","print('Man - Woman + Sister = ',result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"aqjwAlQLsnl9","outputId":"41347828-01b5-4e6a-f73b-989211c7bd6b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["King - Man + Woman =  [('queen', 0.8523604273796082)]\n","France - Paris + Rome =  [('italy', 0.8614554405212402)]\n","France - french + english =  [('england', 0.8093705177307129)]\n","December - November + June =  [('july', 0.9906677603721619)]\n","Man - Woman + Sister =  [('friend', 0.8550175428390503)]\n"]}]},{"cell_type":"markdown","source":["In conclusion, word embeddings are indeed quite capable of capturing and maintaining the semantic relationship between different words."],"metadata":{"id":"79IF3joUsp3S"}},{"cell_type":"markdown","source":["### *3.3. Sentiment Analysis with pretrained GloVe embeddings*"],"metadata":{"id":"BdT-qnm3tmAy"}},{"cell_type":"markdown","source":["##### **Exercise 6**\n","\n","Analyze the vocabulary coverage of the GloVe embeddings on the IMBD dataset. How is it in comparison to the provided Word2Vec model trained on the IMBD corpus?"],"metadata":{"id":"xGt_hnwotMSZ"}},{"cell_type":"code","source":["# <SOL>\n","\n","# </SOL>"],"metadata":{"id":"TQ1koEbkt1Sm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### **Exercise 7**\n","\n","Obtain the embedding representation of the reviews based on GloVe's word vectors, train an SVM classifier with them and evaluate its accuracy. Use the same training and evaluation configuration as in Exercise 5."],"metadata":{"id":"MjCAxfWEuWxo"}},{"cell_type":"code","source":["# <SOL>\n","\n","# </SOL>"],"metadata":{"id":"vn7W4b0Nuwer"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del glove\n","gc.collect()"],"metadata":{"id":"KxqeqCUCzc1d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## *4. FastText*"],"metadata":{"id":"o53v0g-GLUy-"}},{"cell_type":"markdown","source":["### *4.1. Representation of OOV with ad-hoc vs pre-trained fastText model in Gensim*"],"metadata":{"id":"2oc7Ed2dwBtI"}},{"cell_type":"markdown","source":["We will be using [Gensim's implementation to learn word representations via fastText](https://radimrehurek.com/gensim/models/fasttext.html), which allows training word embeddings from a training corpus with the additional ability to obtain word vectors for out-of-vocabulary words.\n","\n","Similar to what we did with Word2Vec, we can obtain the ad-hoc embeddings of our reviews based on the fastText model. Input must be given in the same format as Word2Vec, i.e., as a sequence of sentences, where each sentence is a list of words, that can be given as an iterator for efficient memory management.\n","\n","Many of the construction parameters are common to the Word2Vec class:\n","\n","* `vector_size` (embedding size): the number of dimensions for the vector representation. The default is 100.\n","* `window` (window size): the number of adjacent words that are considered to be in the same context as a target word. The default is 5.\n","* `min_count`: minimum number of times a word must appear in the corpus to be considered in the model.\n","\n","Once trained, we can similarly save/load the model as we saw in Word2Vec."],"metadata":{"id":"sH4_LFKKxBTc"}},{"cell_type":"markdown","source":["##### **Exercise 8**\n","\n","Train a FastText model named ``model_fasttext`` on the IMDB dataset. Use an embedding size of $200$, words must appear in at least $10$ documents to be kept in the model, and a window size of $5$ and random_state $42$. Use the class ``IterableSentence_fromfile`` above defined to create an iterator that yields one sentence (list of utf8 words) after another from the file ``\"imdb_lemmas_clean.txt\"``."],"metadata":{"id":"xvyvFi-Yyv0B"}},{"cell_type":"code","source":["%%time\n","from gensim.models import FastText\n","\n","# <SOL>\n","\n","# </SOL>"],"metadata":{"id":"10GT0_4JyvQn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save model\n","model_fasttext.save(\"model_fastText.model\")\n","\n","# Store just the words + their trained embeddings.\n","word_vectors = model_fasttext.wv\n","word_vectors.save(\"model_fastText.wordvectors\")\n","\n","# Load back with memory-mapping = read-only, shared across processes.\n","fastText_wv = KeyedVectors.load(\"model_fastText.wordvectors\", mmap='r')"],"metadata":{"id":"ZeynOhTj0fjS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del model_fasttext\n","gc.collect()"],"metadata":{"id":"ip9_nLuW0fjS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["By representing the TSNE representation of the fastText embeddings we can see its better ability to group words with the same root (and similar meaning) as opposed to Word2Vec."],"metadata":{"id":"ab349ZEaQp0n"}},{"cell_type":"code","source":["tsne = TSNE(init='random')\n","embed_tsne = tsne.fit_transform(fastText_wv.vectors[:500,:])\n","fig, ax = plt.subplots(figsize=(16, 16))\n","for idx, word in enumerate((list(fastText_wv.key_to_index.keys())[:500])):\n","    plt.scatter(*embed_tsne[idx, :], color='steelblue')\n","    plt.annotate(word, (embed_tsne[idx, 0], embed_tsne[idx, 1]), alpha=0.7)\n","\n","\n","plt.grid()"],"metadata":{"id":"jCsM3NljQ3TZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del embed_tsne\n","gc.collect()"],"metadata":{"id":"4CAjmw0HS_d-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Another interesting thing to look at from the fastText model is its ability to group words with the same root (and similar meaning). This allows fastText's ability to obtain embeddings for out-of-dictionary (OOV) words, as opposed to Word2Vec:"],"metadata":{"id":"mg_vC2eN9VWL"}},{"cell_type":"code","source":["# Wor2Vec for word 'dichlorodiphenyltrichloroethane'\n","word = 'dichlorodiphenyltrichloroethane'\n","if (word in wv.key_to_index):\n","    print(wv[word])\n","else:\n","    print(f'The word {word} does not belong to the dictionary. Wor2Vec cannot assign an embedding.')"],"metadata":{"id":"xR5A95TM20UE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fastText constructs an embedding from the embeddings of the constituent subwords\n","if not (word in fastText_wv.key_to_index):\n","    print(f'The word {word} does not belong to the dictionary. The embedding constructed from the subwords is:\\n')\n","    print(fastText_wv[word])\n","    print('\\nAnd its closest neighbors are:')\n","    print(fastText_wv.most_similar(word))"],"metadata":{"id":"5h3gC8aw255p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The OOV embedding neighbours make little sense since the embedding dictionary was learned on a relatively tiny dataset. Let us now consider the usage of **pre-trained models**.\n","\n","Since we want to keep fastText ability to obtain the embedding representation of OOV, using Gensim's KeyedVectors is not an option, as it only maintains a simple word (as key) to vector (as value) mapping. To solve this issue, we are instead going to be using the library [Compress-fastText\n","](https://pypi.org/project/compress-fasttext/), that allows us to load pretrained fastText models as instances of the class **CompressedFastTextKeyedVectors**, which does synthesize vectors for out-of-vocabulary words.\n"],"metadata":{"id":"OocbKVBs3T4Y"}},{"cell_type":"code","source":["try:\n","  import compress_fasttext\n","except ModuleNotFoundError:\n","  %pip install compress-fasttext\n","  import compress_fasttext"],"metadata":{"id":"V8t0IO5oEKFh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fastTextPre = compress_fasttext.models.CompressedFastTextKeyedVectors.load(\n","    'https://github.com/avidale/compress-fasttext/releases/download/v0.0.4/cc.en.300.compressed.bin'\n",")"],"metadata":{"id":"NTfHxPJQEEpE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if not (word in fastTextPre.key_to_index):\n","    print(f'The word {word} does not belong to the dictionary. The embedding constructed from the subwords is:\\n')\n","    print(fastTextPre[word])\n","    print('\\nAnd its closest neighbors are:')\n","    print(fastTextPre.most_similar(word))"],"metadata":{"id":"fJpbeNc06NnD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["As we can observe now, the OOV embedding neighbours do make sense."],"metadata":{"id":"aCWdcOE1Sgy-"}},{"cell_type":"markdown","source":["### *4.2. Sentiment Analysis with ad-hoc and pre-trained fastText embeddings*"],"metadata":{"id":"RZ7pR81f6qD7"}},{"cell_type":"markdown","source":["##### **Exercise 9**\n","\n","Obtain the embedding representation of the reviews based on the **ad-hoc fastText's word vectors obtained from the IMDB dataset**, train an SVM classifier with them, and evaluate its performance. Use the same training and evaluation configuration as in Exercise 5."],"metadata":{"id":"E1xvVjeb5k17"}},{"cell_type":"code","source":["# <SOL>\n","\n","# </SOL>"],"metadata":{"id":"U70fRjNO3fgo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### **Exercise 10**\n","\n","Obtain the embedding representation of the reviews based on the **pre-trained fastText word vectors**, train an SVM classifier with them, and evaluate its performance. Use the same training and evaluation configuration as in Exercise 5."],"metadata":{"id":"w1RFt61b7TF7"}},{"cell_type":"code","source":["# <SOL>\n","# TODO: Obtain the embedding representation\n","# This part is going to print a lot of message, so it is better if you make the\n","# training of the classifier in the next cell\n","# </SOL>"],"metadata":{"id":"I30oQfPU6WFZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# <SOL>\n","# TODO: Train classifier with pre-trained fastText word vectors\n","# </SOL>"],"metadata":{"id":"mtaaYP-6kEM2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Additionally, the Compress-fastText library allows feeding fastText embeddings to some other model via the ``FastTextTransformer`` class, which makes use of the scikit-learn interface and **represents a text as the average of the embedding of its words**. Hence, we can directly use it for training our SVM on top of fastText as follows:"],"metadata":{"id":"SFxfB4mDjyfc"}},{"cell_type":"code","source":["import compress_fasttext\n","from sklearn.pipeline import make_pipeline\n","from compress_fasttext.feature_extraction import FastTextTransformer\n","\n","corpus_train = [corpus[i] for i in id_train.tolist()]\n","corpus_test = [corpus[i] for i in id_test.tolist()]\n","y_train = Y[id_train]\n","y_test = Y[id_test]\n","\n","parameters = {'kernel':('linear', 'rbf'), 'C':np.arange(1,11,2)}\n","classifier = make_pipeline(\n","    FastTextTransformer(model=fastTextPre),\n","    GridSearchCV(estimator=svm.SVC(), param_grid = parameters, cv = 2, n_jobs=-1)\n",").fit(corpus_train,y_train)\n","classifier.predict(corpus_test)\n","score_fastText_pipeline = classifier.score(corpus_test, y_test)\n","print(\"\\n Accuracy with pre-trained FastText embeddings via FastTextTransformer :\\n\",score_fastText_pipeline)"],"metadata":{"id":"idqh4UPaTGjG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del fastTextPre\n","gc.collect()"],"metadata":{"id":"vvSJxBYK8Hhv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## *5. ELMo*"],"metadata":{"id":"1URYugcELYtP"}},{"cell_type":"markdown","source":["The ELMo model consists of $L = 2$ biLSTM layers with $4,096$ units and $512$ dimension projections and a residual connection from the first to the second layer. It was trained on a really large corpus consisting of $5,5$ billion words. Since ELMo representations are character-based, they can handle OOV words. Additionally, it provides a contextual representation for each word which depends on the entire context in which it is used. You can find more details about both its implementation and pre-trained weights at [AllenNLP's ELMo site](https://allenai.org/allennlp/software/elmo).\n","\n","ELMo embeddings are **deep** because their word representations combine all layers of the deep pre-trained neural network: they result from combining traditional word embeddings and the hidden states from the two biLSTMs. Because embeddings and hidden states both have $512 $dimensions, there is one $512$-dimension embedding and two $512$-dimension hidden states in each direction (one for each layer). That's $1536$ dimensions in each direction, which makes a total of $3072$ dimensions.\n","\n","<img src=\"https://drive.google.com/uc?id=130IQhKGOS3d0WUZ9ameIimbjNSMqP_us\" width=\"70%\">\n","\n","Because both LSTMs use identical inputs, the word embeddings are duplicated. The first two pieces of 512 dimensions are identical to the first 3072 dimensions.\n","\n","<img src=\"https://drive.google.com/uc?id=1NhaDNcTHHYr44le7ofdR4pFa8UyC0omV\" width=\"25%\">\n","\n","Since the classical word embeddings are context-independent, if we obtain the ELMo embeddings of two polysemic words they will share the same values in their first $1024$ dimensions."],"metadata":{"id":"uJHuUDsRLoa3"}},{"cell_type":"markdown","source":["### *5.1. ELMo embeddings in Flair*"],"metadata":{"id":"RXAt6l3HqkvS"}},{"cell_type":"markdown","source":["We could train an ad-hoc ELMo model for our corpus, for example through the [AllenNLP's PyTorch-based NLP framework](https://guide.allennlp.org/), but for the sake of this tutorial we are going to retrieve the ELMo embeddings using the [Flair library](https://pypi.org/project/flair/). Flair is an NLP framework built on top of Pytorch that offers a text embedding library that provides word embeddings and document embeddings for models like ELMo, and BERT, as well as classical word embeddings like GloVe."],"metadata":{"id":"lG21PbD3qgnR"}},{"cell_type":"code","source":["%pip install allennlp==0.9.0\n","import torch\n","%pip install flair==0.4.3\n","import flair\n","%pip install overrides==3.1.0"],"metadata":{"id":"cjmVGsoHk6m-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<font color='red'>Be aware that you will probably need to restart the environment after executing the former cell. You do not need to execute the whole notebook again after it if you are just going to keep on working with this section. Still, make sure that you do execute the cells concerning the imports at the beginning, as well as the steps in **Section 1**; otherwise, you will not have access to the reviews, nor the labels. </font>"],"metadata":{"id":"FkdXlPgS9_Jg"}},{"cell_type":"markdown","source":["Flair data types have two objects, namely **sentence** and **token** objects. Sentences are lists of tokens that hold textual sentences. Then, every text sentence is a Sentence object that is created using the corresponding text."],"metadata":{"id":"pKreANEIj-Zm"}},{"cell_type":"code","source":["sentence1 = \"My investment adviser at my local bank called to discuss my portfolio.\"\n","sentence2 = \"Every day this sweet old lady sits on the same bank at my local park to feed the ducks.\"\n","\n","sentences = [sentence1, sentence2]"],"metadata":{"id":"iUjpfz6kfGxa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from flair.data import Sentence\n","\n","flair_senteces = [Sentence(s) for s in sentences]\n","\n","print(colored('\\n============= Sentence =============', 'blue'))\n","print(sentences[0])\n","print(colored('\\n============= Flair sentence =============', 'blue'))\n","print(flair_senteces[0])"],"metadata":{"id":"H94dpiiekHj5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Specific tokens can be retrieved through either the ``get_token()`` method or the ``tokens`` attribute. Please, note that the first method assumes indexing starts at one, while the attribute approach has the typical zero-based indexing."],"metadata":{"id":"tys29wg1f2Mn"}},{"cell_type":"code","source":["print(flair_senteces[0].get_token(7) == flair_senteces[0].tokens[6])\n","print(flair_senteces[0].get_token(6))"],"metadata":{"id":"mlwUPv_gkJeb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we can use these Sentence objects to retrieve their corresponding ELMo embeddings."],"metadata":{"id":"enPMHh9Fgbup"}},{"cell_type":"code","source":["from flair.embeddings import ELMoEmbeddings\n","\n","elmo_embedding = ELMoEmbeddings()\n","elmo_embedding.embed(flair_senteces)"],"metadata":{"id":"ZwxQ3TAog3nU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The example sentences we created above use the word ``bank`` in a different context. We can see how ELMo embeddings take this into account by assigning two different vectors depending on the context such a word was found in."],"metadata":{"id":"PRl7wo7shHtw"}},{"cell_type":"code","source":["token_bank1 = flair_senteces[0].tokens[6]\n","token_bank2 = flair_senteces[1].tokens[10]\n","\n","print(colored('\\n============= ELMo embedding of BANK in sentence 1 =============', 'blue'))\n","print(token_bank1.embedding)\n","print(colored('\\n============= ELMo embedding of BANK in sentence 2 =============', 'blue'))\n","print(token_bank2.embedding)"],"metadata":{"id":"X-FSQ-Tahr_a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["If we calculate cosine similarity of the words through their embeddings, we can check that the two words are not so similar after all!"],"metadata":{"id":"K1uVJDG_i4N1"}},{"cell_type":"code","source":["import torch.nn as nn\n","\n","similarity = nn.CosineSimilarity(dim=0, eps=1e-6)\n","print(similarity(token_bank1.embedding,token_bank2.embedding))"],"metadata":{"id":"S9A3miUonNAv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can additionally check the two statements that we mentioned at the beginning of this ELMo section:\n","\n","\n","1.   Word embeddings are duplicated\n","2.   Polysemeic words share their first 1024 dimensions\n","\n"],"metadata":{"id":"cWiMySwT509a"}},{"cell_type":"code","source":["print(token_bank1.embedding[0] == token_bank1.embedding[512])\n","print(token_bank1.embedding[0])\n","print(colored('\\n==========================', 'blue'))\n","print((token_bank1.embedding[:1024] == token_bank2.embedding[:1024]).all())"],"metadata":{"id":"XexP6JSH7xCM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Focusing now on our IMBD reviews, one way of vectorizing them is to take the mean of the word embeddings within a review, as follows:\n","\n","  For each sentence:\n","  - Generate word embedding for each word\n","  - Calculate the mean of the embeddings of each word to obtain the embedding of the sentence\n","\n","In such a case, we need to provide the reviews to be embedded by Flair's ELMo as a list of sentences, rather than as a list of lists of tokens, which is what we have right now. So let's first transform our corpus."],"metadata":{"id":"ukkFO8dUn0HU"}},{"cell_type":"code","source":["corpus = corpus_df['clean_review'].tolist()\n","corpus_join = [' '.join(i) for i in corpus]\n","print(colored('\\n============= First review in corpus joint =============', 'blue'))\n","corpus_join[0]"],"metadata":{"id":"CpP9BZOwtgWd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The following cell implements the approach above described. Since it takes quite a long time to execute (around 45 minutes), we have saved for you the resulting NumPy array containing the embeddings. You can download them from [here](https://drive.google.com/file/d/1O0GN_V54C7Dl3R2M98Xr0Qi87dpXtLhn/view?usp=sharing). Save them into your Drive so you can unpickle them directly."],"metadata":{"id":"gS14bNhUoY59"}},{"cell_type":"code","source":["%%time\n","\n","################################################################################\n","# Uncomment the following code if you want to perform the calculation\n","################################################################################\n","'''\n","z = token_bank2.embedding.size()[0]\n","s = torch.zeros(0,z) # Tensor for storing sentence embeddings\n","\n","for review in tqdm(corpus_join):\n","  w = torch.zeros(0,z) # Tensor for words\n","  sentence = Sentence(review)\n","  elmo_embedding.embed(sentence)\n","  for token in sentence:\n","    # Store WE of each word in a sentence\n","    w = torch.cat((w,token.embedding.view(-1,z)),0)\n","  # Store SE (mean of embeddings of all words)\n","  s = torch.cat((s, w.mean(dim = 0).view(-1, z)),0)\n","X = s.numpy()\n","'''\n","\n","################################################################################\n","# Comment the following code if you uncommented the code above\n","################################################################################\n","X = unpickler(\"elmo_embeddings_imbd.pickle\")\n","\n","print(f\"The dimensions of the ELMo embeddings are {X.shape[1]}\")"],"metadata":{"id":"AQ-Rl1AVI_Cm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### *5.2. Sentiment Analysis with Flair's ELMo embeddings*"],"metadata":{"id":"YCz9-qORqtsP"}},{"cell_type":"markdown","source":["##### **Exercise 11**\n","\n","Train an SVM classifier with Flair's ELMo embeddings of the IMDB reviews and evaluate its performance. Use the same training and evaluation configuration as in Exercise 5."],"metadata":{"id":"WTcPR988q2E8"}},{"cell_type":"code","source":["# <SOL>\n","\n","# </SOL>"],"metadata":{"id":"Xqf8hqP_ABcC"},"execution_count":null,"outputs":[]}]}